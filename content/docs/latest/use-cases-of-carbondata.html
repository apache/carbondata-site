<!--
    Licensed to the Apache Software Foundation (ASF) under one
    or more contributor license agreements.  See the NOTICE file
    distributed with this work for additional information
    regarding copyright ownership.  The ASF licenses this file
    to you under the Apache License, Version 2.0 (the
    "License"); you may not use this file except in compliance
    with the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing,
    software distributed under the License is distributed on an
    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.
--><h1>CarbonData Use Cases</h1><p>This tutorial discusses about the problems that CarbonData addresses. It shall take you through the identified top use cases of CarbonData.</p><h2>Introduction</h2><p>For big data interactive analysis scenarios, many customers expect sub-second response to query TB-PB level data on general hardware clusters with just a few nodes.</p><p>In the current big data ecosystem, there are few columnar storage formats such as ORC and Parquet that are designed for SQL on Big Data. Apache Hive?s ORC format is a columnar storage format with basic indexing capability. However, ORC cannot meet the sub-second query response expectation on TB level data, as it performs only stride level dictionary encoding and all analytical operations such as filtering and aggregation is done on the actual data. Apache Parquet is a columnar storage format that can improve performance in comparison to ORC due to its more efficient storage organization. Though Parquet can provide query response on TB level data in a few seconds, it is still far from the sub-second expectation of interactive analysis users. Cloudera Kudu can effectively solve some query performance issues, but kudu is not hadoop native, can?t seamlessly integrate historic HDFS data into new kudu system.</p><p>However, CarbonData uses specially engineered optimizations targeted to improve performance of analytical queries which can include filters, aggregation and distinct counts, the required data to be stored in an indexed, well organized, read-optimized format, CarbonData?s query performance can achieve sub-second response.</p><h2>Motivation: Single Format to provide Low Latency Response for all Use Cases</h2><p>The main motivation behind CarbonData is to provide a single storage format for all the usecases of querying big data on Hadoop. Thus CarbonData is able to cover all use-cases into a single storage format.</p><p><img src="../../../webapp/docs/latest/images/carbon_data_motivation.png?raw=true" alt="Motivation" /></p><h2>Use Cases</h2><h3>Sequential Access</h3>
<ul>
  <li>Supports queries that select only a few columns with a group by clause but do not contain any filters.  This results in full scan over the complete store for the selected columns.</li>
</ul><p><img src="../../../webapp/docs/latest/images/carbon_data_full_scan.png?raw=true" alt="Sequential_Scan" /></p><p><strong>Scenario</strong></p>
<ul>
  <li>ETL jobs</li>
  <li>Log Analysis</li>
</ul><h3>Random Access</h3>
<ul>
  <li>Supports Point Query. These are queries used from operational applications and usually select all or most of the columns and involves a large number of  filters which reduce the result to a small size. Such queries generally do not involve any aggregation or group by clause.
  <ul>
    <li>Row-key query(like HBase)</li>
    <li>Narrow Scan</li>
    <li>Requires second/sub-second level low latency</li>
  </ul></li>
</ul><p><img src="../../../webapp/docs/latest/images/carbon_data_random_scan.png?raw=true" alt="random_access" /></p><p><strong>Scenario</strong></p>
<ul>
  <li>Operational Query</li>
  <li>User Profiling</li>
</ul><h3>Olap Style Query</h3>
<ul>
  <li>Supports Interactive data analysis for any dimensions. These are queries which are typically fired from Interactive Analysis tools.  Such queries often select a few columns and involves filters and group by on a column or a grouping expression.  It also supports queries that :
  <ul>
    <li>Involves aggregation/join</li>
    <li>Roll-up,Drill-down,Slicing and Dicing</li>
    <li>Low-latency ad-hoc query</li>
  </ul></li>
</ul><p><img src="../../../webapp/docs/latest/images/carbon_data_olap_scan.png?raw=true" alt="Olap_style_query" /></p><p><strong>Scenario</strong></p>
<ul>
  <li>Dash-board reporting</li>
  <li>Fraud &amp; Ad-hoc Analysis</li>
</ul>